{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Steam User Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using python to scrape user reviews from the Steam store without using the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Steam store](https://store.steampowered.com/) is the premier online store for video games out there. It's been around since 2003, but in 2013, they added the ability for users to submit their own reviews. These reviews are labeled as either \"Recommended\" or \"Not Recommended\" by the reviewer. This gives you a huge amount of data you can use for your next NLP project. Or perhaps you're just curious about one game in particular. Either way, I'm going to so you how to scrap those reviews using python so you can get all the reviews you want easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting some reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing reviews from one game is pretty easy. Just visit 'https://store.steampowered.com/appreviews/&lt;appid&gt;?json=1' with the app id of whatever game you want at the end. For example: 'https://store.steampowered.com/appreviews/413150?json=1'. To find the app id of a particular game, just check the url on its store page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-app-id image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to get some reviews, it's just as simple as this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import requests\n",
    "response = requests.get(url='https://store.steampowered.com/appreviews/413150?json=1').json()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need the `.json()` call to get the information out of the request, instead of just `<Response [200]>`.\n",
    "\n",
    "Even that can be improved, though. Here is a more easily usable function to get the reviews. The 'params' parameter allows us to put in parameters beyond `json=1`, which we will get to soon. The 'headers' parameter tells Steam that it is a browser making the request, not - for example - a python program pretending to be a browser. It may not be necessary here, but it might help if you are scraping lots of reviews at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import requests\n",
    "\n",
    "def get_reviews(appid, params={'json':1}):\n",
    "        url = 'https://store.steampowered.com/appreviews/'\n",
    "        response = requests.get(url=url+appid, params=params, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        return response.json()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting more reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to those parameters I mentioned. You can see the documentation [here](https://partner.steamgames.com/doc/store/getreviews), but the most important is 'cursor'. If you want more than the maximum 100 reviews you can get from a single request, you'll need to use the cursor. A response includes a 'cursor' attribute, marking which review your request completed on. Including the same cursor in your next request's parameters starts the reviews at the same spot, meaning you get a completely new set of reviews. The cursor is a seemingly random string of characters, and may include characters that need to be encoded to work with a URL request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "params = {'json':1}\n",
    "response = get_reviews(413150, params)\n",
    "cursor = response['cursor']\n",
    "params['cursor'] = cursor.encode()\n",
    "response_2 = get_reviews(413150, params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, to put it into a function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def get_n_reviews(appid, n=100):\n",
    "    reviews = []\n",
    "    cursor = '*'\n",
    "    params = {\n",
    "            'json' : 1,\n",
    "            'filter' : 'all',\n",
    "            'language' : 'english',\n",
    "            'day_range' : 9223372036854775807,\n",
    "            'review_type' : 'all',\n",
    "            'purchase_type' : 'all'\n",
    "            }\n",
    "    \n",
    "    while n > 0:\n",
    "        params['cursor'] = cursor.encode()\n",
    "        params['num_per_page'] = min(100, n)\n",
    "        n -= 100\n",
    "        \n",
    "        response = get_reviews(appid, params)\n",
    "        cursor = response['cursor']\n",
    "        reviews += response['reviews']\n",
    "        \n",
    "        if len(response['reviews']) < 100: break\n",
    "    \n",
    "    return reviews\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the parameters if you'd like, but this grabs the `n` most helpful reviews from all time. The loop at the end ensures you stop taking reviews when you reach the end of all the reviews the game has (at least, those that meet your parameter criteria), and returns all reviews into one list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting an app id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so you've got a way to get a bunch of reviews. But how do you get an app id in the first place? Well I showed earlier how to get the app id of a single game, but that isn't useful if you want to get reviews via python, or to get a bunch of app ids at once. To do this, we are going to have to do a bit of web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_app_id(game_name):\n",
    "    response = requests.get(url=f'https://store.steampowered.com/search/?term={game_name}&category1=998', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    app_id = soup.find(class_='search_result_row')['data-ds-appid']\n",
    "\n",
    "    return app_id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the requests library to get the html from a Steam store search result. the category parameter checks the 'Games' category, ensuring you don't accidentally get a software, demo, soundtrack, or some other store item. Then feed the html of the resulting webpage to a library called BeautifulSoup. BeautifulSoup is a n extremely useful webscraping library. You can check out the documentation [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), but I'll go over some of the basic uses for this blog post.\n",
    "\n",
    "The 'find' method grabs the first html tag the meets the required characteristics. In this case, we will take any tag that has the class 'search_result_row', which is what the Steam store uses for each search result. The index after that method call takes the 'data-ds-appid' attribute of the found tag, which is the attribute the Steam store uses to store the app id of a game in a search result.\n",
    "\n",
    "I've given you these answers here, but if you want to find out the tags and attributes used on some other site, you'll need to do soom digging into the site's html. To find out the html tag of a specific element you see on the site, just right click it and select 'Inspect Element'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting more app ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now you want to get a bunch of app ids at once. Well, you can do that too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def get_n_appids(n=100, filter_by='topsellers'):\n",
    "    appids = []\n",
    "    url = f'https://store.steampowered.com/search/?category1=998&filter={filter_by}&page='\n",
    "    page = 0\n",
    "    \n",
    "    while page*25 < n:\n",
    "        page += 1\n",
    "        response = requests.get(url=url+str(page), headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for row in soup.find_all(class_='search_result_row'):\n",
    "            appids.append(row['data-ds-appid'])\n",
    "    \n",
    "    return appids[:n]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions similarly to the earlier function: it pulls up a search result page from the Steam store, grabs the results, and takes the app ids from those tags. By default this grabs the current 'topsellers', but if you play around with the search page, you can find the url to do whatever search you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first explored scraping these Steam reviews for [an NLP project](https://andrew-muller.medium.com/video-game-review-analysis-3c7602184668) I worked on a bit ago. To gather my data, I used those functions I put up above with a loop to gather all the reviews I needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pandas as pd\n",
    "\n",
    "reviews = []\n",
    "appids = get_n_appids(750)\n",
    "for appid in appids:\n",
    "    reviews += get_n_reviews(appid, 100)\n",
    "df = pd.DataFrame(reviews)[['review', 'voted_up']]\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I actually got too many reviews at first - my computer couldn't handle them all! It was so quick to get thousands of labeled NLP data that was actually interesting to me. It was data that I actually wanted to work with, and so I was driven to do new and more interesting things with this project. I think anything I make will come out better the more interested I am in it. If these reviews are at all interesting to you, hopefully you found something useful in these bits of code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(appid, params=None):\n",
    "        url_start = 'https://store.steampowered.com/appreviews/'\n",
    "        response = requests.get(url=url_start+appid, params=params, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        return response.json() # return data extracted from the json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_reviews(appid, n=100):\n",
    "    reviews = []\n",
    "    cursor = '*'\n",
    "    params = { # https://partner.steamgames.com/doc/store/getreviews\n",
    "            'json' : 1,\n",
    "            'filter' : 'all', # sort by: recent, updated, all (helpfullness)\n",
    "            'language' : 'english', # https://partner.steamgames.com/doc/store/localization\n",
    "            'day_range' : 9223372036854775807, # shows reveiws from all time\n",
    "            'review_type' : 'all', # all, positive, negative\n",
    "            'purchase_type' : 'all', # all, non_steam_purchase, steam\n",
    "        }\n",
    "    while n > 0:\n",
    "        params['cursor'] = cursor.encode() # for pagination\n",
    "        params['num_per_page'] = min(100, n) # 100 is the max possible reviews in one requests\n",
    "        n -= 100\n",
    "        \n",
    "        response = get_reviews(appid, params)\n",
    "        cursor = response['cursor']\n",
    "        reviews += response['reviews']\n",
    "        \n",
    "        if len(response['reviews']) < 100: break\n",
    "    \n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_appids(n=100, filter_by='topsellers'):\n",
    "    appids = []\n",
    "    url = f'https://store.steampowered.com/search/?category1=998&filter={filter_by}&page='\n",
    "    page = 0\n",
    "    \n",
    "    while page*25 < n:\n",
    "        page += 1\n",
    "        response = requests.get(url=url+str(page), headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for row in soup.find_all(class_='search_result_row'):\n",
    "            appids.append(row['data-ds-appid'])\n",
    "    \n",
    "    return appids[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "appids = get_n_appids(750)\n",
    "for appid in appids:\n",
    "    reviews += get_n_reviews(appid, 100)\n",
    "df = pd.DataFrame(reviews)[['review', 'voted_up']]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
